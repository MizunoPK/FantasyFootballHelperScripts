# S9.P2: Epic QC Validation Loop

**Purpose:** Validate the epic as a cohesive whole through systematic validation loop checking ALL 12 dimensions every round until 3 consecutive clean rounds achieved.

**File:** `s9_p2_epic_qc_rounds.md`

**Version:** 2.0 (Updated to use validation loop approach)
**Last Updated:** 2026-02-10

**Stage Flow Context:**
```text
S9.P1 (Epic Smoke Testing) →
→ [YOU ARE HERE: S9.P2 - Epic QC Validation Loop] →
→ S9.P3 (User Testing) → S9.P4 (Epic Final Review) → S10
```

---


## Table of Contents

1. [S9.P2: Epic QC Validation Loop](#s9p2-epic-qc-validation-loop)
2. [MANDATORY READING PROTOCOL](#-mandatory-reading-protocol)
3. [Overview](#overview)
4. [Critical Rules (Epic-Specific)](#-critical-rules-epic-specific)
5. [Prerequisites Checklist](#prerequisites-checklist)
6. [Workflow Overview](#workflow-overview)
7. [12 Dimensions Checklist](#12-dimensions-checklist)
8. [Dimension 8: Cross-Feature Integration](#dimension-8-cross-feature-integration)
9. [Dimension 9: Epic Cohesion](#dimension-9-epic-cohesion)
10. [Dimension 10: Error Handling Consistency](#dimension-10-error-handling-consistency)
11. [Dimension 11: Architectural Alignment](#dimension-11-architectural-alignment)
12. [Dimension 12: Success Criteria Completion](#dimension-12-success-criteria-completion)
13. [Issue Handling: Fix and Continue](#issue-handling-fix-and-continue)
14. [MANDATORY CHECKPOINT 1](#-mandatory-checkpoint-1)
15. [Next Steps](#next-steps)
16. [Summary](#summary)
17. [Exit Criteria](#exit-criteria)

---
## MANDATORY READING PROTOCOL

**BEFORE starting Epic QC Validation Loop, you MUST:**

1. **Read the validation loop guides:**
   - `reference/validation_loop_master_protocol.md` - Core validation loop principles
   - `reference/validation_loop_qc_pr.md` - QC-specific validation patterns
   - Understand 12 dimensions (7 master + 5 epic-specific)
   - Review 3 consecutive clean rounds exit criteria

2. **Use the phase transition prompt** from `prompts/s9_prompts.md`
   - Find "Starting S9: Epic Final QC" prompt
   - Acknowledge validation loop requirements
   - List critical requirements from this guide

3. **Update EPIC_README.md Agent Status** with:
   - Current Phase: S9.P2 - Epic QC Validation Loop
   - Current Guide: `stages/s9/s9_p2_epic_qc_rounds.md`
   - Guide Last Read: {YYYY-MM-DD HH:MM}
   - Critical Rules: "12 dimensions checked every round", "3 consecutive clean rounds required", "Fix issues immediately (no restart)", "100% tests passing"
   - Next Action: Validation Round 1 - Sequential Review

4. **Verify all prerequisites** (see checklist below)

5. **Create VALIDATION_LOOP_LOG.md** in epic folder

6. **THEN AND ONLY THEN** begin validation loop

**This is NOT optional.** Reading the validation loop guides ensures systematic epic-wide validation.

---

## Overview

**What is this guide?**
Epic-level QC Validation Loop validates the epic as a cohesive whole by checking ALL 12 dimensions (7 master + 5 epic-specific) every round until 3 consecutive clean rounds achieved. Unlike the old 3-round approach with different focuses, this validation loop checks ALL concerns EVERY round. See `reference/validation_loop_master_protocol.md` for core principles.

**When do you use this guide?**
- After S9.P1 complete (Epic Smoke Testing passed all 4 parts)
- Ready to perform deep QC validation on epic
- All cross-feature integration verified at basic level

**Key Outputs:**
- VALIDATION_LOOP_LOG.md tracking all rounds
- All 12 dimensions validated every round
- 3 consecutive clean rounds achieved (zero issues found)
- 100% tests passing (verified every round)
- All findings documented in epic_lessons_learned.md
- Ready for S9.P3 (User Testing)

**Time Estimate:**
2-4 hours (typically 5-8 validation rounds)

**Exit Condition:**
Epic QC Validation Loop is complete when 3 consecutive validation rounds find ZERO issues across all 12 dimensions, all tests passing (100%), and epic is validated for user testing

---

## Critical Rules

**See `reference/validation_loop_master_protocol.md` for universal validation loop principles.**

**Epic-specific rules for S9.P2:**

```text
┌─────────────────────────────────────────────────────────────┐
│ CRITICAL RULES - Copy to EPIC_README Agent Status            │
└─────────────────────────────────────────────────────────────┘

1. ⚠️ ALL 12 DIMENSIONS CHECKED EVERY ROUND
   - 7 master dimensions (universal)
   - 5 epic-specific dimensions
   - Cannot skip any dimension
   - Re-read entire epic codebase each round (no working from memory)

2. ⚠️ 3 CONSECUTIVE CLEAN ROUNDS REQUIRED
   - Clean = ZERO issues found across all 12 dimensions
   - Counter resets if ANY issue found
   - Cannot exit early (must achieve 3 consecutive)
   - Typical: 5-8 rounds total to achieve 3 consecutive clean

3. ⚠️ FIX ISSUES IMMEDIATELY (NO RESTART PROTOCOL)
   - If issues found → Fix ALL immediately
   - Re-run tests after fixes (must pass 100%)
   - Continue validation from current round (no restart needed)
   - New approach: Fix and continue vs old: Fix and restart from S9.P1

4. ⚠️ 100% TESTS PASSING MANDATORY
   - Run ALL tests EVERY validation round
   - Must achieve 100% pass rate
   - Any test failure = issue (must fix before next round)
   - Verify tests still pass after code changes

5. ⚠️ FOCUS ON EPIC-LEVEL VALIDATION
   - Feature-level QC done in S7.P2
   - Epic-level focuses on: Integration, consistency, cohesion, success criteria
   - Compare ACROSS ALL features (not individual features)

6. ⚠️ FRESH EYES EVERY ROUND
   - Take 2-5 minute break between rounds
   - Re-read ENTIRE epic codebase using Read tool
   - Use different reading patterns each round
   - Assume everything is wrong (skeptical fresh perspective)
```

**Validation Loop Principles (from master protocol):**
- Assume everything is wrong (start each round skeptical)
- Fresh eyes required (break + re-read between rounds)
- Zero deferred issues (fix ALL before next round)
- Exit only after 3 consecutive clean rounds
- See `reference/validation_loop_master_protocol.md` for complete principles

---

## Prerequisites Checklist

**Before starting Epic QC Validation Loop, verify:**

**S9.P1 complete:**
- [ ] Epic smoke testing PASSED (all 4 parts)
- [ ] Epic smoke test results documented
- [ ] No smoke testing failures

**Epic smoke test plan executed:**
- [ ] All import tests passed
- [ ] All entry point tests passed
- [ ] All E2E execution tests passed with DATA VALUES verified
- [ ] All cross-feature integration tests passed

**Agent Status updated:**
- [ ] EPIC_README.md shows S9.P1 complete
- [ ] Current guide: stages/s9/s9_p2_epic_qc_rounds.md

**Original epic request available:**
- [ ] Have access to {epic_name}.txt
- [ ] Can reference original goals for Round 3

**If any prerequisite fails:**
- Do NOT start Epic QC Validation Loop
- Return to S9.P1 to complete smoke testing
- Verify all prerequisites met before proceeding

---

## Workflow Overview

**See `reference/validation_loop_master_protocol.md` for universal validation loop details.**

**Epic-specific workflow for S9.P2:**

```text
┌─────────────────────────────────────────────────────────────┐
│     S9.P2 EPIC QC VALIDATION LOOP (Until 3 Clean)           │
└─────────────────────────────────────────────────────────────┘

PREPARATION
   ↓ Read validation_loop_master_protocol.md
   ↓ Create VALIDATION_LOOP_LOG.md
   ↓ Run ALL tests (must pass 100%)

ROUND 1: Sequential Review + Test Verification
   ↓ Check ALL 12 dimensions (7 master + 5 epic)
   ↓ Run tests, read code sequentially, verify integration
   ↓
   If issues found → Fix ALL immediately → Re-run tests → Round 2
   If clean → Round 2 (count = 1)

ROUND 2: Reverse Review + Consistency Focus
   ↓ Check ALL 12 dimensions again (fresh eyes)
   ↓ Run tests, read code in reverse, focus on consistency
   ↓
   If issues found → Fix ALL immediately → Re-run tests → Round 3
   If clean → Round 3 (count = 2 or 1 depending on previous)

ROUND 3+: Continue Until 3 Consecutive Clean
   ↓ Check ALL 12 dimensions (different reading patterns)
   ↓ Run tests, spot-checks, success criteria verification
   ↓
   Continue until 3 consecutive rounds with ZERO issues
   ↓
VALIDATION COMPLETE → Proceed to S9.P3 (User Testing)
```

**Key Difference from Old Approach:**
- **Old:** 3 sequential rounds checking different concerns → Any issue → Restart from S9.P1
- **New:** N rounds checking ALL concerns → Fix issues immediately → Continue until 3 consecutive clean

**VALIDATION_LOOP_LOG.md:** Create this file at the start of S9.P2 in the epic folder. Log each round's findings, issues fixed, and clean round counter.

**Time Savings:** 60-180 min per issue (no restart overhead)

---

## 12 Dimensions Checklist

**Check ALL 12 dimensions EVERY validation round.**

**See `reference/validation_loop_master_protocol.md` for master dimension details.**

---

### Master Dimensions (7) - Universal

1. **Empirical Verification** - All interfaces verified from source code
2. **Completeness** - All requirements implemented across epic
3. **Internal Consistency** - No contradictions between features
4. **Traceability** - All code traces to requirements
5. **Clarity & Specificity** - Clear naming, specific errors
6. **Upstream Alignment** - Matches specs and implementation plans
7. **Standards Compliance** - Follows project standards

### Epic-Specific Dimensions (5)

8. **Cross-Feature Integration** - Integration points work correctly
9. **Epic Cohesion** - Consistent patterns across all features
10. **Error Handling Consistency** - Same error patterns across features
11. **Architectural Alignment** - Features use compatible architectures
12. **Success Criteria Completion** - Original epic goals achieved

---

## Dimension 8: Cross-Feature Integration

**Objective:** Validate integration points between features work correctly.

**What to check:**
- Integration points function correctly
- Data flows correctly between features
- Interfaces are compatible
- Error propagation works across boundaries

---

### Validation 1.1: Integration Point Validation

**Review integration points identified in S4 epic_smoke_test_plan.md:**

**Find integration points section:**
```markdown
## Integration Points (example from test plan)
1. Feature 01 (PlayerDataManager) → Feature 02 (RatingSystem)
   - Data flow: Player objects with ADP → Rating system
   - Interface: get_all_players() returns List[Player]

2. Feature 02 (RatingSystem) → Feature 03 (RecommendationEngine)
   - Data flow: Rated players → Recommendation generation
   - Interface: get_rated_players() returns List[RatedPlayer]
```

**For EACH integration point, verify:**

```python
## Integration Test: Feature 01 → Feature 02
from feature_01.PlayerDataManager import PlayerDataManager
from feature_02.RatingSystem import RatingSystem

## Get data from Feature 01
player_mgr = PlayerDataManager()
players = player_mgr.get_all_players()

## Verify data format
assert len(players) > 0, "Feature 01 returned no data"
assert hasattr(players[0], 'adp'), "Players missing ADP field"

## Pass to Feature 02
rating_sys = RatingSystem()
rated_players = rating_sys.apply_ratings(players)

## Verify integration works
assert len(rated_players) == len(players), "Data lost in integration"
assert all(hasattr(p, 'rating') for p in rated_players), "Ratings not applied"

print("✅ Feature 01 → Feature 02 integration validated")
```

**Check ALL integration points** (not just one example)

---

### Validation 1.2: Data Flow Across Features

**Verify data flows correctly through feature chain:**

```python
## Complete data flow: Feature 01 → 02 → 03
from feature_01.PlayerDataManager import PlayerDataManager
from feature_02.RatingSystem import RatingSystem
from feature_03.RecommendationEngine import RecommendationEngine

## Step 1: Get raw data
players = PlayerDataManager().get_all_players()

## Step 2: Apply ratings
rated_players = RatingSystem().apply_ratings(players)

## Step 3: Generate recommendations
recommendations = RecommendationEngine().generate(rated_players)

## Verify complete flow
assert len(recommendations) > 0, "No recommendations generated"
assert recommendations[0]['player_name'] in [p.name for p in players], "Lost player data"
assert 'rating' in recommendations[0], "Lost rating data"
assert 'draft_position' in recommendations[0], "Missing final output"

print("✅ Complete data flow validated")
```

---

### Validation 1.3: Interface Compatibility

**Verify features use compatible interfaces:**

```python
## Check Feature 02 accepts Feature 01's output format
from feature_01.PlayerDataManager import Player
from feature_02.RatingSystem import RatingSystem

## Create sample player (Feature 01 format)
sample_player = Player(name="Test", position="QB", adp=50.0)

## Verify Feature 02 can process it
rating_sys = RatingSystem()
result = rating_sys.rate_player(sample_player)

assert result is not None, "Feature 02 rejected Feature 01 format"
assert hasattr(result, 'rating'), "Feature 02 didn't add rating"

print("✅ Interface compatibility verified")
```

---

### Validation 1.4: Error Propagation Handling

**Test error handling at integration boundaries:**

```python
## Test error propagates correctly
from feature_02.RatingSystem import RatingSystem

try:
    invalid_data = None
    RatingSystem().apply_ratings(invalid_data)
    assert False, "Should have raised error for invalid data"
except ValueError as e:
    assert "Invalid player data" in str(e), "Error message unclear"
    print("✅ Error propagation works")
```

---

### Dimension 8 Issue Examples

**Common issues to look for:**
- Integration point fails (data doesn't flow)
- Interface incompatibilities (type mismatches)
- Data loss during integration
- Error propagation failures
- Suboptimal error messages
- Missing validation at boundaries

**If ANY issues found:**
- Fix ALL immediately
- Re-run tests
- Continue validation (counter resets to 0)

**If ZERO issues found in this dimension:**
- Document clean pass in epic_lessons_learned.md
- Proceed to Round 2

---

## Dimension 9: Epic Cohesion

**Objective:** Validate epic cohesion and consistency across all features.

**What to check:**
- Code style consistent across ALL features
- Naming conventions consistent
- Docstring style consistent
- Import patterns consistent

---

### Validation 2.1: Code Style Consistency

**Check code style is consistent across ALL features:**

**Sample files from each feature:**
```python
## Feature 01 sample
from feature_01.PlayerDataManager import PlayerDataManager

## Feature 02 sample
from feature_02.RatingSystem import RatingSystem

## Feature 03 sample
from feature_03.RecommendationEngine import RecommendationEngine
```

**Check consistency:**
- ✅ Import style consistent (absolute vs relative)
- ✅ Naming conventions consistent (snake_case, PascalCase)
- ✅ Docstring style consistent (Google style)
- ✅ Error handling style consistent (custom exceptions vs standard)

**If inconsistencies found:**
- **Critical:** Core architectural inconsistencies → RESTART
- **Minor:** Naming/style variations → Fix inline, document

---

### Validation 2.2: Naming Convention Consistency

**Check naming is consistent across features:**

```python
## Check method naming patterns
## All features should use similar naming for similar operations

## Feature 01: get_all_players()
## Feature 02: get_rated_players()  ✅ Consistent "get_XXX_players()" pattern
## Feature 03: get_recommendations()  ❌ Different pattern

## If different, decide:
## - Critical (confusing, breaks expectations) → RESTART
## - Minor (just different, still clear) → Document, accept
```

---

## Dimension 10: Error Handling Consistency

**Objective:** Validate error handling is consistent across all features.

**Check error handling is consistent:**

```python
## Do all features use same error handling approach?

## Feature 01
try:
    data = load_data()
except FileNotFoundError:
    raise DataProcessingError("Player data file not found")

## Feature 02
try:
    config = load_config()
except FileNotFoundError:
    raise DataProcessingError("Rating config not found")  # ✅ Consistent

## Feature 03
try:
    settings = load_settings()
except FileNotFoundError:
    return None  # ❌ Different (returns None vs raises error)
```

**Verify:**
- ✅ All features use same error hierarchy
- ✅ Error messages follow same format
- ✅ Error handling at boundaries is consistent

---

## Dimension 11: Architectural Alignment

**Objective:** Validate architectural patterns are consistent across features.

**Check architectural patterns are consistent:**

**Design patterns used:**
- Feature 01: Manager pattern (PlayerDataManager)
- Feature 02: System pattern (RatingSystem)
- Feature 03: Engine pattern (RecommendationEngine)

**Verify:**
- ✅ Patterns are compatible
- ✅ No conflicting architectural approaches
- ✅ Feature boundaries clear and consistent

---

### Dimensions 9-11 Issue Examples

**Common issues to look for:**
- Conflicting architectural patterns
- Incompatible error handling
- Major naming inconsistencies
- Style variations between features

**If ANY issues found:**
- Fix ALL immediately
- Re-run tests
- Continue validation (counter resets to 0)

**If ZERO issues found in dimensions 9-11:**
- Continue checking remaining dimensions

---

## Dimension 12: Success Criteria Completion

**Objective:** Validate epic meets all success criteria and original goals.

**What to check:**
- Original epic request goals achieved
- Epic success criteria from S4 met
- User experience flow works correctly
- Performance meets expectations

---

### Validation 3.1: Validate Against Original Epic Request

**Re-read ORIGINAL {epic_name}.txt:**

Close any current views → Open {epic_name}.txt → Read fresh

**For EACH goal in original request, verify:**

```markdown
## Original Epic Request (example)

User Goal 1: "Integrate ADP data into draft recommendations"
✅ Verified: Feature 01 fetches ADP, Feature 02 applies ratings, Feature 03 uses in recs

User Goal 2: "Allow users to adjust rating multipliers"
✅ Verified: Feature 02 includes multiplier config, Feature 03 respects adjustments

User Goal 3: "Generate top 200 ranked players"
✅ Verified: Feature 03 outputs exactly 200 ranked players
```

**If ANY goal not met:**
- Critical → Create bug fix, RESTART S6
- Can't be met → Get user approval to remove from scope

---

### Validation 3.2: Verify Epic Success Criteria

**From S4 epic_smoke_test_plan.md, check success criteria:**

```markdown
## Epic Success Criteria (example from S4)

1. All 6 positions have rating multipliers (QB, RB, WR, TE, K, DST)
   ✅ Verified: All 6 position files have multipliers

2. Recommendations include player name, position, ADP, rating, draft position
   ✅ Verified: All fields present in output

3. Top player in each position has rating > 0.8
   ✅ Verified: QB top=0.92, RB top=0.88, WR top=0.90, TE top=0.85, K top=0.82, DST top=0.87
```

**All criteria must be met 100%**

---

### Validation 3.3: User Experience Flow Validation

**Execute complete user workflow end-to-end:**

```bash
## Simulated user workflow
python run_script.py --fetch-player-data  # Feature 01
python run_script.py --apply-ratings      # Feature 02
python run_script.py --generate-recs      # Feature 03

## Verify smooth experience
## - No confusing errors
## - Clear progress indicators
## - Expected output files created
## - Help text accurate
```

---

### Validation 3.4: Performance Characteristics

**Check epic meets performance expectations:**

```python
import time

## Time complete workflow
start = time.time()

## Run epic workflow
run_complete_workflow()

elapsed = time.time() - start

## Verify acceptable performance
assert elapsed < 60.0, f"Epic workflow too slow: {elapsed}s (expected <60s)"

print(f"✅ Epic workflow completed in {elapsed:.2f}s")
```

---

### Dimension 12 Issue Examples

**Common issues to look for:**
- Success criteria not met
- Original goals not achieved
- User experience flow problems
- Performance below expectations

**If ANY issues found:**
- Fix ALL immediately
- Re-run tests
- Continue validation (counter resets to 0)

**If ZERO issues found in dimension 12:**
- Check if this completes a clean round

---

## Issue Handling: Fix and Continue

**When issues are found during validation loop:**

### Step 1: Document Issue in VALIDATION_LOOP_LOG.md

```markdown
## Round {N}

### Issues Found:
1. Issue 1: Feature 02 → Feature 03 integration fails with large datasets
2. Issue 2: Inconsistent error handling in Feature 01 vs Feature 03

### Fixes Applied:
1. Fixed data chunking in Feature 02 output method
2. Standardized error handling using DataProcessingError

### Tests After Fix: PASSED (100%)
### Clean Counter: 0 (reset due to issues found)
```

### Step 2: Fix ALL Issues Immediately

- Fix each issue before proceeding
- Re-run ALL tests (must pass 100%)
- Do NOT defer any issues

### Step 3: Continue Validation

- Reset clean counter to 0
- Continue to next validation round
- Check ALL 12 dimensions again with fresh eyes

**Key difference from old approach:**
- **Old:** Any issue → Restart from S9.P1 (smoke testing)
- **New:** Fix immediately → Reset counter → Continue validation

**When restart IS required:**
- User testing (S9.P3) finds bugs → Restart from S9.P1 after bug fixes
- Major architectural issues requiring significant rework → May warrant restart

---

## MANDATORY CHECKPOINT 1

**You have achieved 3 consecutive clean validation rounds**

STOP - DO NOT PROCEED TO S9.P3 YET

**REQUIRED ACTIONS:**
1. [ ] Use Read tool to re-read "Critical Rules" section of this guide
2. [ ] Use Read tool to re-read `reference/validation_loop_master_protocol.md` (7 principles)
3. [ ] Use Read tool to re-read original epic request ({epic_name}.txt)
4. [ ] Verify 3 consecutive clean rounds documented in VALIDATION_LOOP_LOG.md
5. [ ] Verify ALL 12 dimensions checked every round
6. [ ] Update epic_lessons_learned.md with validation findings
7. [ ] Update EPIC_README.md Agent Status:
   - Current Guide: "stages/s9/s9_p3_user_testing.md"
   - Current Step: "S9.P2 complete (3 consecutive clean rounds), ready to start S9.P3"
   - Last Updated: [timestamp]
8. [ ] Output acknowledgment: "CHECKPOINT 1 COMPLETE: Re-read validation loop protocol, verified 3 consecutive clean rounds, ZERO issues"

**Why this checkpoint exists:**
- Ensures validation loop was properly executed
- Confirms all 12 dimensions checked every round
- 3 minutes of verification prevents hours of rework

**ONLY after completing ALL 8 actions above, proceed to Next Steps section**

---

## Next Steps

**If 3 consecutive clean rounds achieved:**
- Document epic QC results in EPIC_README.md
- Update Agent Status: "S9.P2 COMPLETE (3 consecutive clean rounds, zero issues)"
- Update epic_lessons_learned.md with validation findings
- Proceed to **S9.P3: User Testing**

**If still finding issues:**
- Fix ALL issues immediately (no deferring)
- Re-run tests (must pass 100%)
- Reset clean counter to 0
- Continue validation loop until 3 consecutive clean rounds
- Do NOT proceed to User Testing until validation complete

---

## Summary

**Epic-Level QC Validation Loop validates:**
- ALL 12 dimensions checked EVERY round (7 master + 5 epic-specific)
- Continue until 3 consecutive clean rounds achieved
- Fix issues immediately (no restart protocol for S9.P2)

**12 Dimensions Checked:**
1. Empirical Verification (master)
2. Completeness (master)
3. Internal Consistency (master)
4. Traceability (master)
5. Clarity & Specificity (master)
6. Upstream Alignment (master)
7. Standards Compliance (master)
8. Cross-Feature Integration (epic)
9. Epic Cohesion (epic)
10. Error Handling Consistency (epic)
11. Architectural Alignment (epic)
12. Success Criteria Completion (epic)

**Key Differences from Feature-Level (S7.P2):**
- Focus on epic-wide patterns (not individual features)
- Cross-feature integration and architectural consistency
- Validation against original epic request
- 5 epic-specific dimensions vs 5 S7-specific dimensions

**Critical Success Factors:**
- 3 consecutive clean rounds required (exit criteria)
- Fix issues immediately and continue (no restart)
- Fresh eyes through breaks + re-reading
- 100% tests passing every round

**For complete validation loop protocol, see:**
`reference/validation_loop_master_protocol.md`


## Exit Criteria

**Epic QC Validation Loop (S9.P2) is complete when ALL of these are true:**

- [ ] 3 consecutive clean rounds achieved (ZERO issues across all 12 dimensions)
- [ ] All 12 dimensions checked every round (7 master + 5 epic)
- [ ] All tests passing (100% pass rate verified every round)
- [ ] VALIDATION_LOOP_LOG.md complete with all rounds documented
- [ ] Agent Status updated with validation loop completion
- [ ] Ready to proceed to S9.P3 (User Testing)

**If any criterion unchecked:** Continue validation loop until complete

---

**END OF S9.P2 GUIDE**
