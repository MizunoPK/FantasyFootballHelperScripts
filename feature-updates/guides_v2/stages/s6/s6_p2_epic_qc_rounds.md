# S6: Epic-Level Final QC
## S6.P2: Epic QC Rounds

**Purpose:** Validate the epic as a cohesive whole through 3 systematic quality checks focusing on cross-feature integration and epic-wide consistency.

**File:** `s6_p2_epic_qc_rounds.md`

**Stage Flow Context:**
```
S6.P1 (Epic Smoke Testing) â†’
â†’ [YOU ARE HERE: S6.P2 - Epic QC Rounds] â†’
â†’ S6.P3 (User Testing) â†’ S6.P4 (Epic Final Review) â†’ S7
```

---

## ðŸš¨ MANDATORY READING PROTOCOL

**BEFORE starting Epic QC Rounds, you MUST:**

1. **Read the QC rounds pattern:** `reference/qc_rounds_pattern.md`
   - Understand universal 3-round QC workflow
   - Review critical rules that apply to ALL QC rounds
   - Study restart protocol and common mistakes

2. **Use the phase transition prompt** from `prompts/stage_6_prompts.md`
   - Find "Starting S6: Epic Final QC" prompt (covers both 6a and 6b)
   - Acknowledge requirements
   - List critical requirements from this guide

3. **Update EPIC_README.md Agent Status** with:
   - Current Phase: S6.P2 - Epic QC Rounds
   - Current Guide: `stages/s6/s6_p2_epic_qc_rounds.md`
   - Guide Last Read: {YYYY-MM-DD HH:MM}
   - Critical Rules: "3 rounds MANDATORY", "If critical issues â†’ RESTART S6a", "Minor issues can be fixed inline"
   - Next Action: QC Round 1 - Cross-Feature Integration

4. **Verify all prerequisites** (see checklist below)

5. **THEN AND ONLY THEN** begin epic QC rounds

**This is NOT optional.** Reading both the pattern and this guide ensures epic-wide validation.

---

## Quick Start

**What is this guide?**
Epic-level QC Rounds validate the epic as a cohesive whole through 3 systematic quality checks: Cross-Feature Integration (Round 1), Epic Cohesion & Consistency (Round 2), and End-to-End Success Criteria (Round 3). Unlike feature-level QC (S5.P6), these rounds focus on epic-wide patterns and architectural consistency. See `reference/qc_rounds_pattern.md` for universal workflow.

**When do you use this guide?**
- After STAGE_6a complete (Epic Smoke Testing passed)
- Ready to perform deep QC validation on epic
- All cross-feature integration verified at basic level

**Key Outputs:**
- âœ… QC Round 1 complete (cross-feature integration validated)
- âœ… QC Round 2 complete (epic cohesion and consistency verified)
- âœ… QC Round 3 complete (success criteria met, original goals achieved)
- âœ… All findings documented in epic_lessons_learned.md
- âœ… Any issues fixed or bug fixes created

**Time Estimate:**
30-60 minutes (10-20 minutes per round)

**Exit Condition:**
Epic QC Rounds are complete when all 3 rounds pass with zero critical issues, all findings documented, and epic validated against original request

---

## ðŸ›‘ Critical Rules (Epic-Specific)

**ðŸ“– See `reference/qc_rounds_pattern.md` for universal critical rules.**

**Epic-specific rules for S6b:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EPIC-SPECIFIC RULES - Add to EPIC_README Agent Status       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. âš ï¸ Epic Issue Handling (Different from feature-level)
   - Critical issues â†’ Follow epic debugging protocol â†’ RESTART S6a
   - Minor issues â†’ Fix immediately, document, continue (no restart)
   - Epic issues go to: epic_name/debugging/ISSUES_CHECKLIST.md

2. âš ï¸ QC RESTART PROTOCOL (Epic-specific)
   - If Round 1: Critical integration issues â†’ RESTART from S6a
   - If Round 2: Critical consistency issues â†’ RESTART from S6a
   - If Round 3: Critical success criteria failures â†’ RESTART from S6a
   - Minor issues: Fix inline, document, continue
   - Restart destination: S6a (Epic Smoke Testing)

3. âš ï¸ Focus on EPIC-LEVEL validation (not feature-level)
   - Feature-level QC done in S5.P6
   - Epic-level focuses on: Integration, consistency, cohesion
   - Compare ACROSS ALL features (not individual features)

4. âš ï¸ Document findings for EACH round
   - Update epic_lessons_learned.md after each round
   - Include: Issues found, fixes applied, status
   - Serves as evidence of thorough QC
```

**Universal rules (from pattern file):**
- All 3 rounds mandatory
- Each round has unique focus
- Verify DATA VALUES (not just structure)
- Re-reading checkpoints mandatory
- See `reference/qc_rounds_pattern.md` for complete list

---

## Prerequisites Checklist

**Before starting Epic QC Rounds (STAGE_6b), verify:**

**STAGE_6a complete:**
- [ ] Epic smoke testing PASSED (all 4 parts)
- [ ] Epic smoke test results documented
- [ ] No smoke testing failures

**Epic smoke test plan executed:**
- [ ] All import tests passed
- [ ] All entry point tests passed
- [ ] All E2E execution tests passed with DATA VALUES verified
- [ ] All cross-feature integration tests passed

**Agent Status updated:**
- [ ] EPIC_README.md shows STAGE_6a complete
- [ ] Current guide: stages/s6/epic_qc_rounds.md

**Original epic request available:**
- [ ] Have access to {epic_name}.txt
- [ ] Can reference original goals for Round 3

**If any prerequisite fails:**
- âŒ Do NOT start Epic QC Rounds
- Return to STAGE_6a to complete smoke testing
- Verify all prerequisites met before proceeding

---

## Workflow Overview

**ðŸ“– See `reference/qc_rounds_pattern.md` for universal workflow details.**

**Epic-specific workflow for S6b:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EPIC-LEVEL QC ROUNDS (3 Rounds)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Round 1: Cross-Feature Integration (10-20 min)
   â†“ Integration points, data flow, interface compatibility
   â†“ Pass: Zero critical integration issues
   â†“
   If PASS â†’ Round 2
   If CRITICAL ISSUES â†’ Fix, RESTART from S6a

Round 2: Epic Cohesion & Consistency (10-20 min)
   â†“ Code style, naming, error handling, architectural patterns
   â†“ Pass: Zero critical consistency issues
   â†“
   If PASS â†’ Round 3
   If CRITICAL ISSUES â†’ Fix, RESTART from S6a
   If MINOR ISSUES â†’ Fix inline, continue

Round 3: End-to-End Success Criteria (10-20 min)
   â†“ Validate against original epic request
   â†“ Verify epic success criteria met
   â†“ Pass: All criteria met
   â†“
   If PASS â†’ Epic QC complete, proceed to S6c
   If CRITICAL FAILURES â†’ Fix, RESTART from S6a
```

---

## QC Round 1: Cross-Feature Integration

**ðŸ“– See `reference/qc_rounds_pattern.md` for universal Round 1 patterns.**

**Objective:** Validate integration points between features work correctly.

**Time Estimate:** 10-20 minutes

**Pass Criteria:** Zero critical integration issues

---

### Validation 1.1: Integration Point Validation

**Review integration points identified in S4 epic_smoke_test_plan.md:**

**Find integration points section:**
```markdown
## Integration Points (example from test plan)
1. Feature 01 (PlayerDataManager) â†’ Feature 02 (RatingSystem)
   - Data flow: Player objects with ADP â†’ Rating system
   - Interface: get_all_players() returns List[Player]

2. Feature 02 (RatingSystem) â†’ Feature 03 (RecommendationEngine)
   - Data flow: Rated players â†’ Recommendation generation
   - Interface: get_rated_players() returns List[RatedPlayer]
```

**For EACH integration point, verify:**

```python
# Integration Test: Feature 01 â†’ Feature 02
from feature_01.PlayerDataManager import PlayerDataManager
from feature_02.RatingSystem import RatingSystem

# Get data from Feature 01
player_mgr = PlayerDataManager()
players = player_mgr.get_all_players()

# Verify data format
assert len(players) > 0, "Feature 01 returned no data"
assert hasattr(players[0], 'adp'), "Players missing ADP field"

# Pass to Feature 02
rating_sys = RatingSystem()
rated_players = rating_sys.apply_ratings(players)

# Verify integration works
assert len(rated_players) == len(players), "Data lost in integration"
assert all(hasattr(p, 'rating') for p in rated_players), "Ratings not applied"

print("âœ… Feature 01 â†’ Feature 02 integration validated")
```

**Check ALL integration points** (not just one example)

---

### Validation 1.2: Data Flow Across Features

**Verify data flows correctly through feature chain:**

```python
# Complete data flow: Feature 01 â†’ 02 â†’ 03
from feature_01.PlayerDataManager import PlayerDataManager
from feature_02.RatingSystem import RatingSystem
from feature_03.RecommendationEngine import RecommendationEngine

# Step 1: Get raw data
players = PlayerDataManager().get_all_players()

# Step 2: Apply ratings
rated_players = RatingSystem().apply_ratings(players)

# Step 3: Generate recommendations
recommendations = RecommendationEngine().generate(rated_players)

# Verify complete flow
assert len(recommendations) > 0, "No recommendations generated"
assert recommendations[0]['player_name'] in [p.name for p in players], "Lost player data"
assert 'rating' in recommendations[0], "Lost rating data"
assert 'draft_position' in recommendations[0], "Missing final output"

print("âœ… Complete data flow validated")
```

---

### Validation 1.3: Interface Compatibility

**Verify features use compatible interfaces:**

```python
# Check Feature 02 accepts Feature 01's output format
from feature_01.PlayerDataManager import Player
from feature_02.RatingSystem import RatingSystem

# Create sample player (Feature 01 format)
sample_player = Player(name="Test", position="QB", adp=50.0)

# Verify Feature 02 can process it
rating_sys = RatingSystem()
result = rating_sys.rate_player(sample_player)

assert result is not None, "Feature 02 rejected Feature 01 format"
assert hasattr(result, 'rating'), "Feature 02 didn't add rating"

print("âœ… Interface compatibility verified")
```

---

### Validation 1.4: Error Propagation Handling

**Test error handling at integration boundaries:**

```python
# Test error propagates correctly
from feature_02.RatingSystem import RatingSystem

try:
    invalid_data = None
    RatingSystem().apply_ratings(invalid_data)
    assert False, "Should have raised error for invalid data"
except ValueError as e:
    assert "Invalid player data" in str(e), "Error message unclear"
    print("âœ… Error propagation works")
```

---

### Round 1 Checkpoint

**Count critical integration issues:**

**Critical integration issues:**
- Integration point fails (data doesn't flow)
- Interface incompatibilities (type mismatches)
- Data loss during integration
- Error propagation failures

**Minor issues (can fix inline):**
- Suboptimal error messages
- Missing validation at boundaries
- Documentation gaps

**If Round 1 has CRITICAL issues:**
1. Document ALL critical issues
2. Follow epic debugging protocol
3. **RESTART from S6a (epic smoke testing)**

**If Round 1 has only MINOR issues:**
- Fix immediately
- Document in epic_lessons_learned.md
- Continue to Round 2

**If Round 1 has ZERO issues:**
- Document clean pass in epic_lessons_learned.md
- Proceed to Round 2

---

## QC Round 2: Epic Cohesion & Consistency

**ðŸ“– See `reference/qc_rounds_pattern.md` for universal Round 2 patterns.**

**Objective:** Validate epic cohesion and consistency across all features.

**Time Estimate:** 10-20 minutes

**Pass Criteria:** Zero critical consistency issues

---

### Validation 2.1: Code Style Consistency

**Check code style is consistent across ALL features:**

**Sample files from each feature:**
```python
# Feature 01 sample
from feature_01.PlayerDataManager import PlayerDataManager

# Feature 02 sample
from feature_02.RatingSystem import RatingSystem

# Feature 03 sample
from feature_03.RecommendationEngine import RecommendationEngine
```

**Check consistency:**
- âœ… Import style consistent (absolute vs relative)
- âœ… Naming conventions consistent (snake_case, PascalCase)
- âœ… Docstring style consistent (Google style)
- âœ… Error handling style consistent (custom exceptions vs standard)

**If inconsistencies found:**
- **Critical:** Core architectural inconsistencies â†’ RESTART
- **Minor:** Naming/style variations â†’ Fix inline, document

---

### Validation 2.2: Naming Convention Consistency

**Check naming is consistent across features:**

```python
# Check method naming patterns
# All features should use similar naming for similar operations

# Feature 01: get_all_players()
# Feature 02: get_rated_players()  âœ… Consistent "get_XXX_players()" pattern
# Feature 03: get_recommendations()  âŒ Different pattern

# If different, decide:
# - Critical (confusing, breaks expectations) â†’ RESTART
# - Minor (just different, still clear) â†’ Document, accept
```

---

### Validation 2.3: Error Handling Consistency

**Check error handling is consistent:**

```python
# Do all features use same error handling approach?

# Feature 01
try:
    data = load_data()
except FileNotFoundError:
    raise DataProcessingError("Player data file not found")

# Feature 02
try:
    config = load_config()
except FileNotFoundError:
    raise DataProcessingError("Rating config not found")  # âœ… Consistent

# Feature 03
try:
    settings = load_settings()
except FileNotFoundError:
    return None  # âŒ Different (returns None vs raises error)
```

**Verify:**
- âœ… All features use same error hierarchy
- âœ… Error messages follow same format
- âœ… Error handling at boundaries is consistent

---

### Validation 2.4: Architectural Pattern Consistency

**Check architectural patterns are consistent:**

**Design patterns used:**
- Feature 01: Manager pattern (PlayerDataManager)
- Feature 02: System pattern (RatingSystem)
- Feature 03: Engine pattern (RecommendationEngine)

**Verify:**
- âœ… Patterns are compatible
- âœ… No conflicting architectural approaches
- âœ… Feature boundaries clear and consistent

---

### Round 2 Checkpoint

**Count consistency issues:**

**Critical consistency issues:**
- Conflicting architectural patterns
- Incompatible error handling
- Major naming inconsistencies that confuse

**Minor issues:**
- Style variations
- Minor naming differences
- Documentation format variations

**If Round 2 has CRITICAL issues:**
1. Document ALL critical issues
2. Follow epic debugging protocol
3. **RESTART from S6a**

**If Round 2 has MINOR issues:**
- Fix immediately
- Document in epic_lessons_learned.md
- Continue to Round 3

**If Round 2 has ZERO issues:**
- Document clean pass
- Proceed to Round 3

---

## QC Round 3: End-to-End Success Criteria

**ðŸ“– See `reference/qc_rounds_pattern.md` for universal Round 3 patterns.**

**Objective:** Validate epic meets all success criteria and original goals.

**Time Estimate:** 10-20 minutes

**Pass Criteria:** All success criteria met, original goals achieved

---

### Validation 3.1: Validate Against Original Epic Request

**Re-read ORIGINAL {epic_name}.txt:**

Close any current views â†’ Open {epic_name}.txt â†’ Read fresh

**For EACH goal in original request, verify:**

```markdown
## Original Epic Request (example)

User Goal 1: "Integrate ADP data into draft recommendations"
âœ… Verified: Feature 01 fetches ADP, Feature 02 applies ratings, Feature 03 uses in recs

User Goal 2: "Allow users to adjust rating multipliers"
âœ… Verified: Feature 02 includes multiplier config, Feature 03 respects adjustments

User Goal 3: "Generate top 200 ranked players"
âœ… Verified: Feature 03 outputs exactly 200 ranked players
```

**If ANY goal not met:**
- Critical â†’ Create bug fix, RESTART S6a
- Can't be met â†’ Get user approval to remove from scope

---

### Validation 3.2: Verify Epic Success Criteria

**From S4 epic_smoke_test_plan.md, check success criteria:**

```markdown
## Epic Success Criteria (example from S4)

1. All 6 positions have rating multipliers (QB, RB, WR, TE, K, DST)
   âœ… Verified: All 6 position files have multipliers

2. Recommendations include player name, position, ADP, rating, draft position
   âœ… Verified: All fields present in output

3. Top player in each position has rating > 0.8
   âœ… Verified: QB top=0.92, RB top=0.88, WR top=0.90, TE top=0.85, K top=0.82, DST top=0.87
```

**All criteria must be met 100%**

---

### Validation 3.3: User Experience Flow Validation

**Execute complete user workflow end-to-end:**

```bash
# Simulated user workflow
python run_script.py --fetch-player-data  # Feature 01
python run_script.py --apply-ratings      # Feature 02
python run_script.py --generate-recs      # Feature 03

# Verify smooth experience
# - No confusing errors
# - Clear progress indicators
# - Expected output files created
# - Help text accurate
```

---

### Validation 3.4: Performance Characteristics

**Check epic meets performance expectations:**

```python
import time

# Time complete workflow
start = time.time()

# Run epic workflow
run_complete_workflow()

elapsed = time.time() - start

# Verify acceptable performance
assert elapsed < 60.0, f"Epic workflow too slow: {elapsed}s (expected <60s)"

print(f"âœ… Epic workflow completed in {elapsed:.2f}s")
```

---

### Round 3 Checkpoint

**Verify ALL success criteria:**

**If ANY success criteria not met:**
- Document which criteria failed
- Determine if critical (can't achieve epic goals)
- If critical â†’ Create bug fixes, RESTART S6a
- If acceptable â†’ Get user approval, document

**If ALL criteria met:**
- âœ… Epic QC Rounds COMPLETE
- âœ… Document completion in EPIC_README.md
- âœ… Update epic_lessons_learned.md
- âœ… Update Agent Status: "Epic QC Rounds COMPLETE"
- âœ… Proceed to **Step 6: User Testing & Bug Fix Protocol**

---

## Epic Issue Handling Protocol

**If critical issues found during QC rounds:**

### Step 1: Create Epic Debugging Folder

```markdown
epic_name/debugging/ISSUES_CHECKLIST.md

## Issues Found in S6b QC

- [ ] Issue 1: Feature 02 â†’ Feature 03 integration fails with large datasets
- [ ] Issue 2: Inconsistent error handling in Feature 01 vs Feature 03
```

### Step 2: Enter Debugging Protocol

See `debugging/debugging_protocol.md` for complete protocol

### Step 3: After ALL Issues Resolved

**RESTART S6a (Epic Smoke Testing) from Step 1:**
- Re-run ALL 4 smoke test parts
- Verify fixes didn't break anything
- Return to S6b after smoke testing passes

**Critical:** Loop back to Epic Smoke (NOT back to QC round), ensures clean validation

---

## Re-Reading Checkpoint

**After Round 3:**

1. **Re-read Critical Rules** (pattern file + this guide)
2. **Re-read Original Epic Request** ({epic_name}.txt)
3. **Verify ALL success criteria met**
4. **Update EPIC_README.md Agent Status**
5. **Update epic_lessons_learned.md**

---

## Next Steps

**If ALL 3 rounds PASSED:**
- âœ… Document epic QC results in EPIC_README.md
- âœ… Update Agent Status: "Epic QC Rounds COMPLETE (3/3 rounds passed)"
- âœ… Update epic_lessons_learned.md with QC findings
- âœ… Proceed to **Step 6: User Testing & Bug Fix Protocol**

**If ANY round had CRITICAL issues:**
- âŒ Fix ALL critical issues
- âŒ Follow epic debugging protocol
- âŒ **RESTART from S6a (epic smoke testing)**
- âŒ Re-run smoke testing â†’ QC Round 1 â†’ QC Round 2 â†’ QC Round 3
- âŒ Do NOT proceed to PR Review until clean pass

---

## Summary

**Epic-Level QC Rounds validate:**
- Round 1: Cross-feature integration (do features work together?)
- Round 2: Epic cohesion & consistency (is epic architecturally sound?)
- Round 3: End-to-end success criteria (does epic achieve goals?)

**Key Differences from Feature-Level:**
- Focus on epic-wide patterns (not individual features)
- Minor issues can be fixed inline (epic-level more flexible)
- Critical issues require epic debugging protocol
- Restart destination: S6a (epic smoke testing)
- Validation against original epic request (Round 3)

**Critical Success Factors:**
- All 3 rounds mandatory
- Focus on integration and consistency (not individual features)
- Minor vs critical issue classification
- Epic debugging protocol for critical issues
- Validation against original user goals

**ðŸ“– For universal patterns and detailed validation techniques, see:**
`reference/qc_rounds_pattern.md`

---

**END OF STAGE 6b GUIDE**
