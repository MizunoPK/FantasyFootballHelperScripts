# Feature Lessons Learned: score_penalty_application

**Part of Epic:** nfl_team_penalty
**Feature Number:** 2
**Created:** 2026-01-12
**Last Updated:** 2026-01-13

---

## Purpose

This document captures lessons specific to THIS feature's development. This is separate from epic_lessons_learned.md (which captures cross-feature patterns).

---

## S2 Lessons Learned (Feature Deep Dive)

### Critical Mistake 1: Autonomous Resolution of Checklist Items

**Date:** 2026-01-13
**Phase:** S2.P3 Phase 6 (Acceptance Criteria)
**Severity:** HIGH (Direct violation of zero autonomous resolution rule)

#### What Happened

User requested: "Add a checklist item - ensure that the simulation works still after the parameter is introduced"

**My actions:**
1. ‚úÖ Added Question 1 to checklist (CORRECT)
2. ‚úÖ Investigated simulation code (CORRECT)
3. ‚ùå Marked Question 1 as "RESOLVED" (WRONG - only users can resolve)
4. ‚ùå Added Requirement 9 to spec.md based on unapproved answer (WRONG)
5. ‚ùå Updated acceptance criteria prematurely (WRONG)

**User correction:** "The guides should require my express sign off on ALL checklist items"

#### Root Cause Analysis

**Why this happened:**
1. **Overconfidence after research** - Finding an answer made me feel the question was "done"
2. **Conflated "investigation complete" with "question resolved"**
3. **Misunderstanding of agent vs user roles**
   - Agent role: Research, investigate, present findings
   - User role: Review findings, make decisions, approve
4. **Missing the human-in-the-loop principle** - Forgot that user must validate ALL agent findings

#### What Should Have Happened

**Correct workflow:**
1. User asks for simulation compatibility check
2. Agent adds Question 1 to checklist (status: OPEN)
3. Agent investigates comprehensively
4. Agent presents findings (status: PENDING USER APPROVAL)
5. User reviews, asks follow-ups
6. Agent investigates follow-ups
7. User says "approved"
8. **ONLY THEN** agent marks as RESOLVED
9. Agent adds requirement with source: "User Answer to Question 1"

**Key distinction:**
- "Investigation complete" ‚Üí Status: PENDING USER APPROVAL
- "User approved" ‚Üí Status: RESOLVED

#### Prevention Strategies

**For agents:**
1. **ALWAYS use "PENDING USER APPROVAL" status after investigation**
2. **Never mark questions resolved without explicit user approval**
3. **Two-step process:**
   - Step 1: Investigate ‚Üí Present ‚Üí Mark PENDING
   - Step 2: User approves ‚Üí Update spec ‚Üí Mark RESOLVED

---

### Critical Mistake 2: Incomplete Investigation Scope

**Date:** 2026-01-13
**Phase:** S2.P3 Phase 6 (Acceptance Criteria)
**Severity:** MEDIUM (Incomplete research, caught by user before causing issues)

#### What Happened

User asked: "ensure that the simulation works still after the parameter is introduced"

**My initial investigation:**
- ‚úÖ Checked where simulations call score_player()
- ‚ùå Didn't check ConfigManager instantiation

**User follow-up:** "What about when ConfigManagers are created? Investigate if there will be any issues when *reading* the config json files"

#### Root Cause Analysis

**Why this happened:**
1. **Narrow interpretation** - User said "parameter" ‚Üí I only checked parameter passing
2. **Lack of systematic investigation framework** - No mental checklist
3. **Overconfidence** - Found answer quickly ‚Üí assumed complete
4. **Missing systems thinking** - Didn't map ALL intersection points between feature and simulations

#### What Should Have Happened

**Comprehensive investigation checklist for "simulation compatibility":**

**Category 1: Method/Function Calls** ‚úì (did this)
- Where do simulations call score_player()?
- Do they pass new parameter?
- Is default value correct?

**Category 2: Configuration/Data Loading** ‚úó (missed this initially)
- Where do simulations create ConfigManager?
- How does ConfigManager load new config keys?
- What if JSON missing keys?

**Category 3: Integration Points**
- Does new code affect simulation flow?
- Other simulation files affected?

**Category 4: Timing/Dependencies**
- Transition period issues?
- Implementation sequencing?

**Category 5: Edge Cases**
- Old config with new code?
- New config with old code?

#### Prevention Strategies

**For agents:**
1. **Use systematic investigation frameworks** - Don't rely on intuition
2. **Ask "what else?" 3 times** - Keep asking until genuinely no other possibilities
3. **Think in systems, not components** - Map ALL interaction points
4. **When investigating compatibility, check:**
   - Method calls ‚úì
   - Data loading ‚úì
   - Configuration ‚úì
   - Integration points ‚úì
   - Timing/sequencing ‚úì

---

### Recommendations for Guide Updates

#### 1. Update S2.P3 Refinement Guide

**Add to Critical Rules section:**

```markdown
1.5. ‚ö†Ô∏è INVESTIGATION COMPLETE ‚â† QUESTION RESOLVED
   - Agent investigates ‚Üí Status: PENDING USER APPROVAL
   - User explicitly approves ‚Üí Status: RESOLVED
   - NEVER mark questions as resolved without explicit user approval
```

#### 2. Update Checklist Template

**Add to top of file:**

```markdown
## üö® CRITICAL: Agent vs User Roles

**Agent Role:** Create questions, investigate, present findings, mark PENDING
**User Role:** Review findings, make decisions, approve resolutions

**AGENTS CANNOT:**
- ‚ùå Mark questions as RESOLVED (only users can)
- ‚ùå Assume approval (even if answer seems obvious)
- ‚ùå Add requirements based on unapproved answers

**Status Progression:**
1. Question added ‚Üí OPEN
2. Agent investigates ‚Üí PENDING USER APPROVAL
3. User approves ‚Üí RESOLVED
```

#### 3. Update CLAUDE.md Anti-Patterns Section

**Add new section:**

```markdown
## Anti-Patterns to Avoid

### Anti-Pattern 1: Autonomous Checklist Resolution

**WRONG:** Agent investigates ‚Üí Marks RESOLVED ‚Üí Adds requirement
**CORRECT:** Agent investigates ‚Üí Marks PENDING ‚Üí User approves ‚Üí Agent marks RESOLVED

**Key distinction:** Research findings ‚â† User approval

### Anti-Pattern 2: Narrow Investigation Scope

**WRONG:** Check most obvious aspect ‚Üí Declare complete
**CORRECT:** Use systematic checklist covering all categories

**Key distinction:** Use systematic frameworks, don't rely on intuition
```

#### 4. Create Investigation Checklist Reference

**New file:** `feature-updates/guides_v2/reference/investigation_checklists.md`

Include checklists for common investigation types:
- Simulation compatibility (6 categories)
- Backward compatibility
- Integration testing
- Cross-feature conflicts

#### 5. Update S2.P2 Guide (Specification Phase)

**Add to Phase 2.6:**

```markdown
**If user requests investigation:**
- Add question with status: OPEN
- Investigate thoroughly
- Present findings with status: PENDING USER APPROVAL
- Wait for explicit approval
- ONLY THEN mark as resolved

**Remember:** Investigation complete ‚â† Question resolved
```

---

### Summary

**Key Lessons:**
1. **Research findings ‚â† User approval** - Always wait for explicit sign-off
2. **Investigation complete ‚â† Question resolved** - Use "PENDING" until user approves
3. **Narrow scope = incomplete answer** - Use systematic checklists
4. **Think in systems, not components** - Map ALL interaction points

**Prevention:**
- Use explicit status markers (PENDING vs RESOLVED)
- Follow two-step process (investigate ‚Üí wait ‚Üí approve ‚Üí resolve)
- Use investigation checklists (don't rely on intuition)
- Ask "what else?" multiple times

**Impact:**
- Low actual impact (caught and corrected immediately)
- High educational value (documented for future reference)
- Guide improvements proposed (prevent recurrence)

**Action Items:**
- [ ] Update S2.P3 guide with anti-pattern warning
- [ ] Update checklist template with role definitions
- [ ] Update CLAUDE.md with anti-pattern examples
- [ ] Create investigation_checklists.md reference
- [ ] Update S2.P2 with post-presentation protocol

---

## S5 Lessons Learned (TODO Creation)

_To be populated during S5_

---

## S6 Lessons Learned (Implementation)

_To be populated during S6_

---

## S7 Lessons Learned (Post-Implementation)

_To be populated during S7_
