## OBJECTIVE PLANNING WORKFLOW

Before starting changes, follow this mandatory workflow:

### **STEP 1: Create Draft TODO File**

Create an initial TODO file that maps out all the tasks needed to accomplish the objective. This draft is based solely on the original specification file (`updates/{objective_name}.txt`). The TODO file should be named `updates/todo-files/{objective_name}_todo.md`.

The draft TODO should include:
- High-level phases and tasks
- Anticipated file modifications
- Testing requirements
- Documentation updates

As you complete tasks, keep the file updated with your progress in case a new Claude agent in a new session needs to finish the work. Ensure this TODO file has everything it needs to maintain consistent work - including a note about keeping the file up to date on progress made.

### **STEP 2: First Verification Round (5 Iterations)**

Execute the TODO FILE VERIFICATION AND REFINEMENT PROTOCOL (detailed below) with **5 complete iterations** to research the codebase, identify patterns, and refine the draft TODO file. This happens BEFORE creating the questions file.

**Iteration Breakdown**:
- **Iterations 1-3**: Standard verification (research, cross-reference, refine)
- **Iteration 4**: Continue refinement with deeper technical details
- **Iteration 5**: **SKEPTICAL RE-VERIFICATION** - Assume nothing written so far is accurate. Re-verify ALL claims, assumptions, file paths, method names, patterns, and implementation strategies from scratch. Question everything and validate with fresh codebase research.

### **STEP 3: Create Questions File**

After completing the first 5 verification iterations (including skeptical re-verification), create a questions file based on ambiguities, implementation choices, and user preference decisions discovered during codebase research. The questions file should be named `updates/{objective_name}_questions.md`.

This file should contain:
- Clarifying questions about requirements
- Implementation approach options (with recommendations based on codebase research)
- User preference questions
- Questions that arose during the first verification round

**IMPORTANT**: Wait for the user to answer these questions before proceeding to Step 4.

### **STEP 4: Update TODO with Question Answers**

After receiving user answers, update the TODO file to reflect:
- User's chosen implementation approaches
- Clarified requirements from answers
- Adjusted task priorities based on answers
- Any new tasks revealed by the answers

### **STEP 5: Second Verification Round (7 More Iterations)**

Execute the TODO FILE VERIFICATION AND REFINEMENT PROTOCOL again with **7 additional complete iterations** to:
- Validate that question answers are fully integrated
- Research any new patterns needed based on answers
- Refine implementation details
- Finalize task order and dependencies

**Iteration Breakdown**:
- **Iterations 6-8**: Verification with user answers integrated
- **Iteration 9**: Continue refinement with implementation-specific details
- **Iteration 10**: **SKEPTICAL RE-VERIFICATION** - Again, assume nothing is accurate. Re-verify ALL claims, especially those based on user answers. Validate that answers are correctly interpreted and integrated. Fresh codebase research required.
- **Iterations 11-12**: Final refinement and preparation for implementation

After completing both verification rounds (**12 total iterations**), the TODO file should be comprehensive, thoroughly validated, and ready for implementation.

---

## TODO FILE VERIFICATION AND REFINEMENT PROTOCOL

**üö® MANDATORY** - This iterative verification protocol must be executed:
1. After creating the draft TODO file (5 iterations - including skeptical re-verification)
2. After receiving user's answers to questions (7 more iterations - including skeptical re-verification)

### **WHEN TO EXECUTE**:
- ‚úÖ Immediately after generating the draft TODO file (STEP 2 - First 5 iterations)
- ‚úÖ After updating TODO with user's question answers (STEP 5 - Second 7 iterations)
- ‚úÖ Before beginning any implementation work

### **ITERATIVE REFINEMENT PROCESS (12 TOTAL ITERATIONS)**:

**üìã ITERATION 1: Initial Verification**

1. **Re-read ALL Source Documents**:
   - Open and carefully read the original `updates/{objective_name}.txt` file line-by-line
   - Open and carefully read the `updates/{objective_name}_questions.md` answers section (if Step 5 - second verification round)
   - Open and carefully read your TODO file `updates/todo-files/{objective_name}_todo.md`

2. **Cross-Reference Requirements**:
   - Extract EVERY requirement from the original updates file (explicit and implied)
   - Extract EVERY requirement from the question answers (if Step 5 - second verification round)
   - Compare against TODO file to verify ALL requirements are covered
   - Mark any missing requirements: ‚ùå MISSING FROM TODO
   - During first verification round (Step 2): Identify ambiguities to ask about in questions file

3. **Ask Clarifying Questions to Self**:
   - What specific files will need to be modified for each task?
   - What existing patterns or utilities in the codebase can be leveraged?
   - Are there any edge cases or error scenarios not covered?
   - What test files will need to be created or modified?
   - Are there any dependencies between tasks that need ordering?
   - What existing code should be examined before implementation?

4. **Research Codebase**:
   - Use Glob/Grep to find relevant existing code
   - Look for similar implementations to maintain consistency
   - Identify utility classes or helper functions to reuse
   - Find test file patterns to follow
   - Locate configuration files that may need updates

5. **Update TODO File**:
   - Add missing requirements as new tasks
   - Add specific file paths to each task
   - Add code references (e.g., "Similar to ClassName.method_name in file.py:line")
   - Add test requirements for each implementation task
   - Refine task descriptions with more technical specificity
   - Add prerequisite relationships between tasks

**üìã ITERATION 2: Deep Dive Verification**

1. **Re-read Updated TODO File**:
   - Review all changes made in Iteration 1
   - Check if new questions emerged from codebase research

2. **Ask Additional Clarifying Questions**:
   - What data structures will be passed between functions?
   - What error handling strategies should be used?
   - Are there any performance considerations?
   - What logging should be added for debugging?
   - Should any constants be extracted to configuration files?
   - What documentation needs to be updated?
   - Are there any backward compatibility concerns?

3. **Research Additional Code Patterns**:
   - Find error handling patterns used in similar code
   - Identify logging patterns and conventions
   - Check configuration file structures
   - Review existing documentation formats
   - Look for data validation patterns

4. **Update TODO File Again**:
   - Add error handling tasks
   - Add logging requirements
   - Add documentation update tasks
   - Add data validation requirements
   - Refine implementation order based on dependencies
   - Add code review checkpoints

**üìã ITERATION 3: Deep Dive Verification**

1. **Re-read ALL Documents One More Time**:
   - Original updates file
   - Question answers (if Step 5 - second verification round)
   - Fully refined TODO file (for this round)

2. **Ask Final Technical Questions**:
   - Are there any integration points with other modules not addressed?
   - What mock objects will be needed for testing?
   - Are there any circular dependency risks?
   - What happens if operations fail midway through?
   - Are all file paths absolute or properly constructed?
   - What cleanup operations are needed if errors occur?

3. **Research Integration Points**:
   - Use Grep to find all places existing code is called
   - Identify all modules that might be affected
   - Check for potential circular imports
   - Review existing test mock patterns

4. **TODO Update**:
   - Add integration testing tasks
   - Add cleanup/rollback requirements
   - Add verification steps for each phase
   - Add pre-commit validation checkpoints
   - Ensure every task has specific, actionable steps
   - Confirm task order prevents breaking the system

**üìã ITERATION 4: Enhanced Technical Detail**

1. **Implementation-Specific Research**:
   - Research exact method signatures needed
   - Identify return types and data structures
   - Find example usages of similar patterns in codebase
   - Document edge cases with code examples

2. **Performance and Optimization**:
   - Consider performance implications of approach
   - Identify potential bottlenecks
   - Research caching strategies if needed
   - Document any async/await patterns needed

3. **TODO Enhancement**:
   - Add specific code examples to tasks
   - Document exact API endpoints/parameters
   - Add performance considerations
   - Include optimization opportunities

**üìã ITERATION 5 (First Round) / ITERATION 10 (Second Round): SKEPTICAL RE-VERIFICATION**

üö® **CRITICAL**: Assume NOTHING written so far is accurate. Start fresh.

1. **Question Everything**:
   - Is the file path I documented actually correct? (Verify with Read/Glob)
   - Does that method I referenced actually exist? (Verify with Grep)
   - Is that pattern I identified actually used? (Re-search codebase)
   - Are my assumptions about data flow correct? (Re-trace through code)
   - Did I misunderstand the original requirement? (Re-read specification)

2. **Fresh Codebase Validation**:
   - Re-search for ALL file paths mentioned in TODO
   - Re-verify ALL method names and line numbers
   - Re-validate ALL code patterns claimed
   - Re-check ALL dependencies and imports
   - Re-examine ALL test patterns documented

3. **Requirement Re-Verification**:
   - Re-read original specification word-by-word
   - Re-read user question answers (if second round)
   - List requirements again from scratch
   - Compare new list against TODO
   - Identify discrepancies or misinterpretations

4. **Comprehensive Corrections**:
   - Fix any incorrect file paths
   - Correct any wrong method names
   - Update any misunderstood patterns
   - Revise any flawed implementation strategies
   - Document what was corrected and why

5. **Document Re-Verification**:
   - Add "Skeptical Re-Verification Results" section to TODO
   - List what was verified as correct
   - List what was found to be incorrect and corrected
   - Document confidence level in current plan

**üìã ITERATIONS 6-9 (Second Round): Standard Verification**

Continue with standard verification process (same as Iterations 1-4) but with user answers integrated.

**üìã ITERATIONS 11-12 (Second Round): Final Preparation**

1. **Final Integration Check**:
   - Verify all user answers are reflected in implementation plan
   - Cross-check dependencies one final time
   - Validate testing strategy is comprehensive
   - Confirm documentation updates are complete

2. **Implementation Readiness**:
   - Ensure every task is actionable and clear
   - Verify no ambiguities remain
   - Confirm all code references are accurate
   - Validate execution order is optimal

3. **Risk Assessment**:
   - Document remaining risks
   - Identify potential blockers
   - Plan mitigation strategies
   - Set success criteria

### **DOCUMENTATION REQUIREMENTS**:

After completing each verification round, add/update a "Verification Summary" section to the TODO file documenting:
- ‚úÖ Number of iterations completed (5 for first round, 12 total after second round)
- ‚úÖ Number of requirements added after initial draft
- ‚úÖ Key codebase patterns/utilities identified for reuse
- ‚úÖ Critical dependencies or ordering requirements
- ‚úÖ Risk areas identified during research
- ‚úÖ Questions identified for user clarification (first round)
- ‚úÖ Question answers integrated into plan (second round)
- ‚úÖ **Skeptical re-verification results** (corrections made, confidence level)

### **ACCEPTANCE CRITERIA** (before beginning implementation):
- ‚úÖ First verification round complete (5 iterations on draft TODO, including skeptical re-verification)
- ‚úÖ Questions file created with thoughtful, research-backed questions
- ‚úÖ User answers received for all questions
- ‚úÖ Second verification round complete (7 more iterations with answers integrated, including second skeptical re-verification)
- ‚úÖ **Total: 12 complete verification iterations performed** (with 2 skeptical re-verifications)
- ‚úÖ Every requirement from original file covered in TODO
- ‚úÖ Every question answer reflected in TODO tasks
- ‚úÖ Specific file paths identified for each task (verified multiple times)
- ‚úÖ Existing code patterns researched and documented (validated in skeptical phases)
- ‚úÖ Test requirements specified for each implementation
- ‚úÖ Task dependencies and ordering verified
- ‚úÖ Edge cases and error scenarios addressed
- ‚úÖ Documentation update tasks included
- ‚úÖ Pre-commit validation checkpoints added
- ‚úÖ **All claims and assumptions verified through skeptical re-verification**

### **ENFORCEMENT**:
- **NO SHORTCUTS**: Cannot skip iterations or rush through verification
- **TWO ROUNDS REQUIRED**: Must complete both verification rounds (5 iterations + 7 iterations = 12 total)
- **SKEPTICAL PHASES MANDATORY**: Must complete iteration 5 and iteration 10 as skeptical re-verifications
- **QUESTIONS REQUIRED**: Must create questions file after first verification round
- **NO ASSUMPTIONS**: Must research codebase to validate approach
- **NO VAGUE TASKS**: Each task must have specific technical details
- **ITERATIVE IS MANDATORY**: Minimum 12 total cycles of read-question-research-update
- **DOCUMENT THE PROCESS**: Verification summary required in TODO file after each round
- **FRESH EYES REQUIRED**: Skeptical iterations must approach verification as if seeing the plan for the first time

### **WHY THIS MATTERS**:
Thorough TODO preparation with skeptical re-verification prevents:
- ‚ùå Discovering missing requirements mid-implementation
- ‚ùå Breaking existing functionality due to unforeseen dependencies
- ‚ùå Inconsistent code that doesn't match project patterns
- ‚ùå Incomplete implementations that miss edge cases
- ‚ùå Failed tests due to inadequate test planning
- ‚ùå Rework and refactoring caused by poor initial planning
- ‚ùå **Incorrect assumptions about code structure or API behavior**
- ‚ùå **Pursuing implementation strategies based on misunderstood patterns**
- ‚ùå **Building on top of incorrect file paths or method references**

**The skeptical re-verification phases (iterations 5 and 10) are critical** because they force the agent to:
1. Challenge its own assumptions
2. Re-validate all claims with fresh codebase research
3. Catch errors that might have been overlooked in earlier iterations
4. Ensure the plan is built on accurate, verified information

A well-researched, thoroughly verified, and skeptically re-validated TODO file is the foundation of successful implementation.
Immediately after creating the TODO file, create a code changes documentation file in the updates folder (NOT the done folder yet) named `{objective_name}_code_changes.md`. This file should be updated incrementally as you work through each task in the TODO file. After completing each significant change, immediately document it in the code changes file with: file paths, line numbers, before/after code snippets, rationale, and impact. This ensures the documentation stays current and accurate throughout the implementation process. The file will be moved to updates/done when the objective is complete.
After updates are complete, verify that all unit tests still pass and test the system to ensure it is functional. Test ALL unit tests across the entire repo. All tests across the entire repo must pass before we can mark an objective as complete. Make this a very clear and important TODO item.
Create any new unit tests to cover the new implementations, and modify any relevant unit tests and test them to ensure they pass.
Update rules files and readme files according to the new changes.
When the objective is complete, ensure the code changes documentation file is comprehensive and finalized. It should detail all code modifications made during the implementation, including: specific file paths and line numbers, before/after code snippets, rationale for each change, impact analysis, configuration changes, test modifications, and verification of files that were checked but not modified. This serves as a complete technical reference for understanding exactly what changed and why. Move this file from updates/ to updates/done/ along with the objective file.
Once the objective is completely done, then move the associated file in updates to the 'done' folder contained within the same updates directory. Also delete the questions file once the objective is complete.
Be VERY systematic when creating the TODO file and proceeding with the implementation. Break the objective up into modualized components. Each phase that is outlined in the todo file should leave the repo is a state that is still testable and functional, and should run the pre-commit checklist in its entirety. Do not skip any unit tests or interactive integration tests just because you think that the tests will not be effected by the change - assume everything is at risk of breaking no matter what you do.

## REQUIREMENT VERIFICATION PROTOCOL

**üö® CRITICAL: FINAL VERIFICATION BEFORE MARKING OBJECTIVE COMPLETE** - This protocol must be executed before claiming an objective is complete:

### **WHEN TO EXECUTE**:
- ‚úÖ After all implementation work appears to be complete
- ‚úÖ Before moving objective files to updates/done/
- ‚úÖ Before deleting questions files
- ‚úÖ Before claiming "objective complete" to the user

### **MANDATORY VERIFICATION STEPS**:

**üìã STEP 1: Re-read Original Requirements File**
- Open and read EVERY LINE of the original `updates/{objective_name}.txt` file
- Create a checklist of EVERY requirement mentioned (numbered or implied)
- For each requirement, verify it has been implemented
- Mark each requirement as ‚úÖ DONE or ‚ùå MISSING

**üìã STEP 2: Re-read Question Answers File**
- Open and read EVERY ANSWER in `updates/{objective_name}_questions.md`
- Create a checklist of EVERY answer that implies implementation work
- For each answer, verify the implementation matches what was answered
- Mark each answer as ‚úÖ IMPLEMENTED or ‚ùå NOT IMPLEMENTED

**üìã STEP 3: Search Codebase for Implementation**
- Use Grep/Glob tools to search for evidence of each requirement
- Verify files were actually modified as required
- Check that new files were created if specified
- Confirm no placeholder code or TODOs remain

**üìã STEP 4: Identify Missing Requirements**
- If ANY requirement is ‚ùå MISSING or ‚ùå NOT IMPLEMENTED:
  - STOP immediately
  - Create a new completion TODO file: `updates/todo-files/{objective_name}_completion_todo.md`
  - Document ALL missing requirements
  - Implement missing requirements before proceeding
  - Re-run this verification protocol

**üìã STEP 5: Document Verification**
- Add a "Requirements Verification" section to the code changes file
- List each requirement and its implementation status
- Include file paths and line numbers as evidence
- Confirm 100% requirement coverage

### **ACCEPTANCE CRITERIA**:
- ‚úÖ ALL requirements from original file implemented (100% coverage)
- ‚úÖ ALL question answers reflected in implementation
- ‚úÖ NO missing functionality or partial implementations
- ‚úÖ NO half-measures or "mostly complete" status
- ‚úÖ Evidence of implementation exists in codebase (files, code, tests)
- ‚úÖ All unit tests pass (100%)
- ‚úÖ Manual testing confirms functionality works

### **ENFORCEMENT**:
- **NO EXCEPTIONS**: If even ONE requirement is missing, objective is NOT complete
- **NO PARTIAL CREDIT**: "90% complete" = incomplete, must finish remaining 10%
- **NO ASSUMPTIONS**: Just because something seems done doesn't mean it is - verify with code
- **RE-VERIFICATION REQUIRED**: If new requirements discovered, re-run entire protocol

### **FAILURE TO VERIFY = INCOMPLETE OBJECTIVE**:
If this protocol is not executed, or if missing requirements are discovered after claiming completion, the objective must be reopened and completed properly. The user must be notified of any missing requirements immediately.

## PRE-COMMIT VALIDATION PROTOCOL

**üö® MANDATORY FOR EVERY STAGE COMPLETION** - This protocol must be executed at the completion of EVERY phase, step, or significant change before proceeding to the next stage:

### **WHEN TO EXECUTE**:
- ‚úÖ After completing ANY phase step (e.g., Phase 2 Step 2.1)
- ‚úÖ Before moving to the next phase or step
- ‚úÖ When instructed to "validate and commit" or "commit changes"
- ‚úÖ At any major milestone or completion point
- ‚úÖ Before asking user for validation to proceed

### **MANDATORY EXECUTION STEPS**:

**üöÄ REQUIRED: Run Unit Tests**

Run the unit test suite to validate all changes:

```bash
python tests/run_all_tests.py
```

This command executes ALL unit tests:
- ‚úÖ Complete unit test suite in tests/ directory
- ‚úÖ Strict 100% pass requirement
- ‚úÖ Returns exit code 0 for success, 1 for failure

**Exit Codes**:
- `0` = All tests passed (100%), safe to commit
- `1` = Some tests failed, DO NOT COMMIT until issues are fixed

**Test Options**:
```bash
python tests/run_all_tests.py --verbose    # Show individual test names
python tests/run_all_tests.py --detailed   # Full test output
python tests/run_all_tests.py --single     # Faster single command mode
```

**Validation Steps**:

1. **ANALYZE CHANGES**:
   ```bash
   git status
   git diff
   ```
   - Review ALL changed files
   - Understand impact of changes

2. **ADD/UPDATE UNIT TESTS**:
   - Add tests for new functionality in `tests/` directory
   - Follow test structure: `tests/module_path/test_FileName.py`
   - Use proper mocking to isolate functionality
   - Ensure tests follow Arrange-Act-Assert pattern

3. **RUN ALL UNIT TESTS** (MANDATORY):
   ```bash
   python tests/run_all_tests.py
   ```
   - **100% pass rate required**
   - Fix any failing tests before proceeding
   - Re-run until all tests pass

4. **MANUAL TESTING** (if applicable):
   - Test the affected functionality manually
   - Run the main scripts to verify behavior:
     ```bash
     python run_league_helper.py   # League helper mode
     python run_player_fetcher.py  # Player data fetcher
     python run_simulation.py      # Simulation system
     ```

5. **UPDATE DOCUMENTATION**:
   - Update README.md if functionality changed
   - Update CLAUDE.md if workflow or architecture changed
   - Update rules.txt if development process changed
   - Update module-specific documentation as needed

6. **COMMIT STANDARDS**:
   - Format: "Brief description of change"
   - Keep under 50 characters when possible
   - NO emojis or icons
   - Do NOT include "Generated with Claude Code" footer
   - List major changes in commit body if needed

### **FAILURE PROTOCOL**:
- **If ANY test fails**: STOP immediately, fix the issue, re-run tests
- **If unit tests fail**: Fix failing tests, ensure 100% pass rate before proceeding
- **No exceptions**: Cannot proceed to next phase without 100% test success
- **Cannot commit**: Do NOT commit code with failing tests

### **ENFORCEMENT**:
- This protocol is MANDATORY and NON-NEGOTIABLE for every stage completion
- Violation of this protocol requires immediate correction and re-validation
- The user should be notified if this protocol was not followed properly
