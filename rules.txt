Before starting changes, ask clarifying questions by creating a questions file in the updates folder. The questions file should be named with the pattern: `{objective_name}_questions.md`. This file should contain all clarifying questions that would help better understand and complete the objective. Wait for the user to answer these questions before creating the TODO file and beginning development. If new questions arise during development, pause and add them to the questions file.
After receiving answers to clarifying questions, create a TODO file that maps out all the tasks that will need to be completed to accomplish this objective. As you complete the tasks, keep the file updated with your progress just in case a new Claude agent in a new session needs to finish the work. Ensure this TODO file has everything it needs to maintain consistent work - including a note about keeping the file up to date on progress made. Put the TODO file in the todo-files folder in the updates directory.

## TODO FILE VERIFICATION AND REFINEMENT PROTOCOL

**üö® MANDATORY AFTER GENERATING TODO FILE** - This iterative verification protocol must be executed after creating the initial TODO file and before beginning implementation:

### **WHEN TO EXECUTE**:
- ‚úÖ Immediately after generating the initial TODO file
- ‚úÖ After receiving user's answers to clarifying questions
- ‚úÖ Before beginning any implementation work

### **ITERATIVE REFINEMENT PROCESS (MINIMUM 3 ITERATIONS)**:

**üìã ITERATION 1: Initial Verification**

1. **Re-read ALL Source Documents**:
   - Open and carefully read the original `updates/{objective_name}.txt` file line-by-line
   - Open and carefully read the `updates/{objective_name}_questions.md` answers section
   - Open and carefully read your newly created `updates/todo-files/{objective_name}_todo.md`

2. **Cross-Reference Requirements**:
   - Extract EVERY requirement from the original updates file (explicit and implied)
   - Extract EVERY requirement from the question answers
   - Compare against TODO file to verify ALL requirements are covered
   - Mark any missing requirements: ‚ùå MISSING FROM TODO

3. **Ask Clarifying Questions to Self**:
   - What specific files will need to be modified for each task?
   - What existing patterns or utilities in the codebase can be leveraged?
   - Are there any edge cases or error scenarios not covered?
   - What test files will need to be created or modified?
   - Are there any dependencies between tasks that need ordering?
   - What existing code should be examined before implementation?

4. **Research Codebase**:
   - Use Glob/Grep to find relevant existing code
   - Look for similar implementations to maintain consistency
   - Identify utility classes or helper functions to reuse
   - Find test file patterns to follow
   - Locate configuration files that may need updates

5. **Update TODO File**:
   - Add missing requirements as new tasks
   - Add specific file paths to each task
   - Add code references (e.g., "Similar to ClassName.method_name in file.py:line")
   - Add test requirements for each implementation task
   - Refine task descriptions with more technical specificity
   - Add prerequisite relationships between tasks

**üìã ITERATION 2: Deep Dive Verification**

1. **Re-read Updated TODO File**:
   - Review all changes made in Iteration 1
   - Check if new questions emerged from codebase research

2. **Ask Additional Clarifying Questions**:
   - What data structures will be passed between functions?
   - What error handling strategies should be used?
   - Are there any performance considerations?
   - What logging should be added for debugging?
   - Should any constants be extracted to configuration files?
   - What documentation needs to be updated?
   - Are there any backward compatibility concerns?

3. **Research Additional Code Patterns**:
   - Find error handling patterns used in similar code
   - Identify logging patterns and conventions
   - Check configuration file structures
   - Review existing documentation formats
   - Look for data validation patterns

4. **Update TODO File Again**:
   - Add error handling tasks
   - Add logging requirements
   - Add documentation update tasks
   - Add data validation requirements
   - Refine implementation order based on dependencies
   - Add code review checkpoints

**üìã ITERATION 3: Final Verification**

1. **Re-read ALL Documents One More Time**:
   - Original updates file
   - Question answers
   - Fully refined TODO file

2. **Ask Final Technical Questions**:
   - Are there any integration points with other modules not addressed?
   - What mock objects will be needed for testing?
   - Are there any circular dependency risks?
   - What happens if operations fail midway through?
   - Are all file paths absolute or properly constructed?
   - What cleanup operations are needed if errors occur?

3. **Research Integration Points**:
   - Use Grep to find all places existing code is called
   - Identify all modules that might be affected
   - Check for potential circular imports
   - Review existing test mock patterns

4. **Final TODO Update**:
   - Add integration testing tasks
   - Add cleanup/rollback requirements
   - Add verification steps for each phase
   - Add pre-commit validation checkpoints
   - Ensure every task has specific, actionable steps
   - Confirm task order prevents breaking the system

### **DOCUMENTATION REQUIREMENTS**:

After completing 3+ iterations, add a "Verification Summary" section to the TODO file documenting:
- ‚úÖ Number of iterations completed (minimum 3)
- ‚úÖ Number of requirements added after initial draft
- ‚úÖ Key codebase patterns/utilities identified for reuse
- ‚úÖ Critical dependencies or ordering requirements
- ‚úÖ Risk areas identified during research

### **ACCEPTANCE CRITERIA**:
- ‚úÖ At least 3 complete verification iterations performed
- ‚úÖ Every requirement from original file covered in TODO
- ‚úÖ Every question answer reflected in TODO tasks
- ‚úÖ Specific file paths identified for each task
- ‚úÖ Existing code patterns researched and documented
- ‚úÖ Test requirements specified for each implementation
- ‚úÖ Task dependencies and ordering verified
- ‚úÖ Edge cases and error scenarios addressed
- ‚úÖ Documentation update tasks included
- ‚úÖ Pre-commit validation checkpoints added

### **ENFORCEMENT**:
- **NO SHORTCUTS**: Cannot skip iterations or rush through verification
- **NO ASSUMPTIONS**: Must research codebase to validate approach
- **NO VAGUE TASKS**: Each task must have specific technical details
- **ITERATIVE IS MANDATORY**: Minimum 3 cycles of read-question-research-update
- **DOCUMENT THE PROCESS**: Verification summary required in TODO file

### **WHY THIS MATTERS**:
Thorough TODO preparation prevents:
- ‚ùå Discovering missing requirements mid-implementation
- ‚ùå Breaking existing functionality due to unforeseen dependencies
- ‚ùå Inconsistent code that doesn't match project patterns
- ‚ùå Incomplete implementations that miss edge cases
- ‚ùå Failed tests due to inadequate test planning
- ‚ùå Rework and refactoring caused by poor initial planning

A well-researched, thoroughly verified TODO file is the foundation of successful implementation.
Immediately after creating the TODO file, create a code changes documentation file in the updates folder (NOT the done folder yet) named `{objective_name}_code_changes.md`. This file should be updated incrementally as you work through each task in the TODO file. After completing each significant change, immediately document it in the code changes file with: file paths, line numbers, before/after code snippets, rationale, and impact. This ensures the documentation stays current and accurate throughout the implementation process. The file will be moved to updates/done when the objective is complete.
After updates are complete, verify that all unit tests still pass and test the system to ensure it is functional. Test ALL unit tests across the entire repo. All tests across the entire repo must pass before we can mark an objective as complete. Make this a very clear and important TODO item.
Create any new unit tests to cover the new implementations, and modify any relevant unit tests and test them to ensure they pass.
Update rules files and readme files according to the new changes.
When the objective is complete, ensure the code changes documentation file is comprehensive and finalized. It should detail all code modifications made during the implementation, including: specific file paths and line numbers, before/after code snippets, rationale for each change, impact analysis, configuration changes, test modifications, and verification of files that were checked but not modified. This serves as a complete technical reference for understanding exactly what changed and why. Move this file from updates/ to updates/done/ along with the objective file.
Once the objective is completely done, then move the associated file in updates to the 'done' folder contained within the same updates directory. Also delete the questions file once the objective is complete.
Be VERY systematic when creating the TODO file and proceeding with the implementation. Break the objective up into modualized components. Each phase that is outlined in the todo file should leave the repo is a state that is still testable and functional, and should run the pre-commit checklist in its entirety. Do not skip any unit tests or interactive integration tests just because you think that the tests will not be effected by the change - assume everything is at risk of breaking no matter what you do.

## REQUIREMENT VERIFICATION PROTOCOL

**üö® CRITICAL: FINAL VERIFICATION BEFORE MARKING OBJECTIVE COMPLETE** - This protocol must be executed before claiming an objective is complete:

### **WHEN TO EXECUTE**:
- ‚úÖ After all implementation work appears to be complete
- ‚úÖ Before moving objective files to updates/done/
- ‚úÖ Before deleting questions files
- ‚úÖ Before claiming "objective complete" to the user

### **MANDATORY VERIFICATION STEPS**:

**üìã STEP 1: Re-read Original Requirements File**
- Open and read EVERY LINE of the original `updates/{objective_name}.txt` file
- Create a checklist of EVERY requirement mentioned (numbered or implied)
- For each requirement, verify it has been implemented
- Mark each requirement as ‚úÖ DONE or ‚ùå MISSING

**üìã STEP 2: Re-read Question Answers File**
- Open and read EVERY ANSWER in `updates/{objective_name}_questions.md`
- Create a checklist of EVERY answer that implies implementation work
- For each answer, verify the implementation matches what was answered
- Mark each answer as ‚úÖ IMPLEMENTED or ‚ùå NOT IMPLEMENTED

**üìã STEP 3: Search Codebase for Implementation**
- Use Grep/Glob tools to search for evidence of each requirement
- Verify files were actually modified as required
- Check that new files were created if specified
- Confirm no placeholder code or TODOs remain

**üìã STEP 4: Identify Missing Requirements**
- If ANY requirement is ‚ùå MISSING or ‚ùå NOT IMPLEMENTED:
  - STOP immediately
  - Create a new completion TODO file: `updates/todo-files/{objective_name}_completion_todo.md`
  - Document ALL missing requirements
  - Implement missing requirements before proceeding
  - Re-run this verification protocol

**üìã STEP 5: Document Verification**
- Add a "Requirements Verification" section to the code changes file
- List each requirement and its implementation status
- Include file paths and line numbers as evidence
- Confirm 100% requirement coverage

### **ACCEPTANCE CRITERIA**:
- ‚úÖ ALL requirements from original file implemented (100% coverage)
- ‚úÖ ALL question answers reflected in implementation
- ‚úÖ NO missing functionality or partial implementations
- ‚úÖ NO half-measures or "mostly complete" status
- ‚úÖ Evidence of implementation exists in codebase (files, code, tests)
- ‚úÖ All unit tests pass (100%)
- ‚úÖ Manual testing confirms functionality works

### **ENFORCEMENT**:
- **NO EXCEPTIONS**: If even ONE requirement is missing, objective is NOT complete
- **NO PARTIAL CREDIT**: "90% complete" = incomplete, must finish remaining 10%
- **NO ASSUMPTIONS**: Just because something seems done doesn't mean it is - verify with code
- **RE-VERIFICATION REQUIRED**: If new requirements discovered, re-run entire protocol

### **FAILURE TO VERIFY = INCOMPLETE OBJECTIVE**:
If this protocol is not executed, or if missing requirements are discovered after claiming completion, the objective must be reopened and completed properly. The user must be notified of any missing requirements immediately.

## PRE-COMMIT VALIDATION PROTOCOL

**üö® MANDATORY FOR EVERY STAGE COMPLETION** - This protocol must be executed at the completion of EVERY phase, step, or significant change before proceeding to the next stage:

### **WHEN TO EXECUTE**:
- ‚úÖ After completing ANY phase step (e.g., Phase 2 Step 2.1)
- ‚úÖ Before moving to the next phase or step
- ‚úÖ When instructed to "validate and commit" or "commit changes"
- ‚úÖ At any major milestone or completion point
- ‚úÖ Before asking user for validation to proceed

### **MANDATORY EXECUTION STEPS**:

**üöÄ REQUIRED: Run Unit Tests**

Run the unit test suite to validate all changes:

```bash
python tests/run_all_tests.py
```

This command executes ALL unit tests:
- ‚úÖ Complete unit test suite in tests/ directory
- ‚úÖ Strict 100% pass requirement
- ‚úÖ Returns exit code 0 for success, 1 for failure

**Exit Codes**:
- `0` = All tests passed (100%), safe to commit
- `1` = Some tests failed, DO NOT COMMIT until issues are fixed

**Test Options**:
```bash
python tests/run_all_tests.py --verbose    # Show individual test names
python tests/run_all_tests.py --detailed   # Full test output
python tests/run_all_tests.py --single     # Faster single command mode
```

**Validation Steps**:

1. **ANALYZE CHANGES**:
   ```bash
   git status
   git diff
   ```
   - Review ALL changed files
   - Understand impact of changes

2. **ADD/UPDATE UNIT TESTS**:
   - Add tests for new functionality in `tests/` directory
   - Follow test structure: `tests/module_path/test_FileName.py`
   - Use proper mocking to isolate functionality
   - Ensure tests follow Arrange-Act-Assert pattern

3. **RUN ALL UNIT TESTS** (MANDATORY):
   ```bash
   python tests/run_all_tests.py
   ```
   - **100% pass rate required**
   - Fix any failing tests before proceeding
   - Re-run until all tests pass

4. **MANUAL TESTING** (if applicable):
   - Test the affected functionality manually
   - Run the main scripts to verify behavior:
     ```bash
     python run_league_helper.py   # League helper mode
     python run_player_fetcher.py  # Player data fetcher
     python run_simulation.py      # Simulation system
     ```

5. **UPDATE DOCUMENTATION**:
   - Update README.md if functionality changed
   - Update CLAUDE.md if workflow or architecture changed
   - Update rules.txt if development process changed
   - Update module-specific documentation as needed

6. **COMMIT STANDARDS**:
   - Format: "Brief description of change"
   - Keep under 50 characters when possible
   - NO emojis or icons
   - Do NOT include "Generated with Claude Code" footer
   - List major changes in commit body if needed

### **FAILURE PROTOCOL**:
- **If ANY test fails**: STOP immediately, fix the issue, re-run tests
- **If unit tests fail**: Fix failing tests, ensure 100% pass rate before proceeding
- **No exceptions**: Cannot proceed to next phase without 100% test success
- **Cannot commit**: Do NOT commit code with failing tests

### **ENFORCEMENT**:
- This protocol is MANDATORY and NON-NEGOTIABLE for every stage completion
- Violation of this protocol requires immediate correction and re-validation
- The user should be notified if this protocol was not followed properly
